{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc7c8269-4dd9-44f5-8ef7-42dc731ce596",
   "metadata": {},
   "source": [
    "## Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms\n",
    "\n",
    "\n",
    "In machine learning algorithms, there is a close relationship between polynomial functions and kernel functions, particularly in the context of Support Vector Machines (SVMs). Both polynomial functions and kernel functions are used to introduce non-linearity to the data, allowing machine learning algorithms to handle non-linearly separable datasets.\n",
    "\n",
    "Polynomial Functions:\n",
    "Polynomial functions are mathematical functions that involve powers of a variable (e.g., x) raised to different exponents. A polynomial function of degree d is represented as:\n",
    "f(x) = a_d * x^d + a_{d-1} * x^{d-1} + ... + a_2 * x^2 + a_1 * x + a_0\n",
    "\n",
    "where a_d, a_{d-1}, ..., a_1, a_0 are coefficients, and d is the degree of the polynomial. For example, a quadratic polynomial has a degree of 2, a cubic polynomial has a degree of 3, and so on.\n",
    "\n",
    "In machine learning, polynomial functions can be used to transform the original feature space into a higher-dimensional space. For instance, given a 2-dimensional feature vector (x, y), a quadratic polynomial transformation would map it to a 6-dimensional space (x^2, xy, y^2, x, y, 1). This higher-dimensional space may make the data points linearly separable, even if they were not separable in the original feature space.\n",
    "\n",
    "Kernel Functions:\n",
    "Kernel functions are similarity functions that compute the inner product or similarity between two data points in the original feature space, without explicitly transforming the data into a higher-dimensional space. Kernel functions work implicitly, making them computationally efficient, especially when dealing with high-dimensional data.\n",
    "The kernel trick is a technique used in SVMs, where the SVM replaces the dot product of feature vectors with a kernel function. The decision function for an SVM with a kernel becomes:\n",
    "\n",
    "f(x_new) = sign(Σ(α_i * y_i * K(x_new, x_i)) + b)\n",
    "\n",
    "where K(x_new, x_i) is the kernel function, and α_i and y_i are the coefficients and labels of the support vectors in the training set.\n",
    "\n",
    "Notably, polynomial kernels are a type of kernel function used in SVMs to introduce polynomial non-linearity without explicitly transforming the data. The polynomial kernel is defined as:\n",
    "\n",
    "K(x, x') = (γ * x^T * x' + r)^d\n",
    "\n",
    "where γ is a scaling factor, r is an optional term, and d is the degree of the polynomial.\n",
    "\n",
    "Relationship:\n",
    "The relationship between polynomial functions and kernel functions lies in their ability to introduce non-linearity to the data. Polynomial functions explicitly transform the data into higher-dimensional spaces, whereas kernel functions achieve non-linearity implicitly, without the need to compute the explicit transformation. In other words, polynomial functions and polynomial kernels can achieve similar effects in terms of non-linear transformation for handling non-linearly separable data, but the kernel approach is often more computationally efficient, especially for high-dimensional datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed34723-7025-4770-8df3-6aff21d98058",
   "metadata": {},
   "source": [
    "## Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e117c8-ae94-4ad5-9ea4-ab9d4ee049ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e34ebb93-2965-4f38-a5ad-fb4a0a06e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.data\n",
    "y=dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd70e39-959f-49d4-b597-acf18a186b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train ,y_test = train_test_split(X,y , test_size=0.30 , random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4252982c-4c77-4cfe-9581-d43899dd6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel='poly',degree=3 , gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "621b525f-71b1-4710-ab42-e0783140ec44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;poly&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed18370-3367-4c4c-b0c7-800f7dee8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6ca9f2-44fe-4556-b282-21aeb8feaefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6378b-c6be-4b42-9e5e-a7eabfbe0001",
   "metadata": {},
   "source": [
    "## Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "\n",
    "In Support Vector Regression (SVR), epsilon (ε) is a hyperparameter that defines the width of the epsilon-insensitive tube around the regression line. This tube determines the region within which errors (residuals) are not penalized, as long as they fall within the epsilon distance from the actual target values.\n",
    "\n",
    "The number of support vectors in SVR can be affected by increasing the value of epsilon in the following way:\n",
    "\n",
    "Larger Epsilon (Wider Tube):\n",
    "When the value of epsilon is increased, the epsilon-insensitive tube becomes wider. This means that a larger margin is allowed for errors, and data points can fall further away from the regression line without incurring a penalty, as long as they are within the wider epsilon-insensitive tube.\n",
    "\n",
    "More Support Vectors:\n",
    "As the epsilon-insensitive tube widens, it is more likely to encompass additional data points. These data points lying within the wider tube are known as support vectors since they either lie on the margin boundary or have errors (residuals) within the tube. When epsilon is larger, it becomes more likely for data points to fall within this tube, leading to an increase in the number of support vectors.\n",
    "\n",
    "Less Sensitivity to Outliers:\n",
    "A larger epsilon value implies that the SVR model is less sensitive to individual outliers that fall within the widened epsilon-insensitive tube. Outliers that fall beyond the tube width would still be penalized, but those falling within the wider tube contribute less to the loss function, reducing their impact on the model's training.\n",
    "\n",
    "More Flexible Model:\n",
    "Increasing epsilon introduces more flexibility to the SVR model. The model allows larger deviations from the regression line within the wider tube, making it less strict in enforcing a tight fit to the training data. This increased flexibility can be beneficial when dealing with noisy datasets or datasets that exhibit more significant variations.\n",
    "\n",
    "In summary, increasing the value of epsilon in SVR results in a wider epsilon-insensitive tube, leading to more support vectors and a more flexible model. It reduces the model's sensitivity to individual data points and outliers, allowing for a looser fit to the training data, which might be useful when dealing with noisy or complex datasets. However, it's essential to balance the value of epsilon to prevent overfitting and ensure a well-generalized model. The appropriate value of epsilon should be chosen based on the specific characteristics of the dataset and the desired trade-off between model flexibility and generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8735219b-9815-4528-b05a-a6893d2da93e",
   "metadata": {},
   "source": [
    "## Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "\n",
    "The performance of Support Vector Regression (SVR) is heavily influenced by the choice of kernel function and several hyperparameters: C, epsilon, and gamma. Each parameter serves a specific purpose in SVR, and their values can significantly impact the model's predictive performance and generalization ability. Let's explore each parameter and how it affects SVR:\n",
    "\n",
    "\n",
    "Kernel Function:\n",
    "\n",
    "The kernel function is crucial in SVR as it determines the type of non-linear mapping that allows SVR to model non-linear relationships between the input features and the target variable. Commonly used kernel functions in SVR are:\n",
    "a. Linear Kernel: K(x, x') = x^T * x'\n",
    "b. Polynomial Kernel: K(x, x') = (gamma * x^T * x' + r)^d\n",
    "c. Radial Basis Function (RBF) Kernel: K(x, x') = exp(-gamma * ||x - x'||^2)\n",
    "Increasing the complexity of the kernel function (e.g., using a polynomial or RBF kernel) allows SVR to fit more intricate and non-linear patterns in the data. However, a more complex kernel can lead to overfitting, especially when the dataset is small or noisy. For simpler datasets, a linear kernel might suffice, while for more complex datasets, a polynomial or RBF kernel could be more appropriate.\n",
    "\n",
    "C Parameter (Regularization):\n",
    "\n",
    "The C parameter is a regularization hyperparameter in SVR that controls the trade-off between fitting the training data and minimizing the model's complexity. It influences the width of the epsilon-insensitive tube, determining the balance between model flexibility and penalizing large errors. Higher values of C result in a narrower margin (less tolerance for errors), potentially leading to overfitting, while lower values of C increase the margin (more tolerance for errors), potentially leading to underfitting.\n",
    "Increase C: Use a higher C value when you have high confidence in the data quality and wish to achieve a tight fit to the training data. This is suitable when the data is clean, and you want the SVR model to prioritize fitting the training data closely.\n",
    "\n",
    "Decrease C:\n",
    "\n",
    "Use a lower C value when you have noisy or sparse data or want to avoid overfitting. A lower C encourages a wider margin, making the model more tolerant to errors and better at generalizing to unseen data.\n",
    "Epsilon Parameter (Tube Width):\n",
    "The epsilon parameter determines the width of the epsilon-insensitive tube around the regression line. Data points falling within this tube do not contribute to the loss function and are considered support vectors. Larger values of epsilon allow more data points to be within the tube, leading to a looser fit to the training data.\n",
    "Increase Epsilon: Use a larger epsilon value when you expect the target variable to have some noise or uncertainty. This makes the model less sensitive to individual data points, improving its robustness to noise and variations in the target variable.\n",
    "\n",
    "Decrease Epsilon: Use a smaller epsilon value when you want a stricter fit to the training data and have high confidence in the accuracy of the target variable.\n",
    "\n",
    "Gamma Parameter (Kernel Coefficient):\n",
    "\n",
    "The gamma parameter is specific to the RBF kernel. It defines the width of the Gaussian kernel and affects the influence of each training example on the decision boundary. A higher gamma makes the decision boundary more sensitive to individual data points, potentially leading to overfitting.\n",
    "\n",
    "Increase Gamma:\n",
    "Use a higher gamma value when you expect a sharp decision boundary and have confidence in the distribution of the data. This can help capture fine details in the data, but be cautious of overfitting.\n",
    "\n",
    "Decrease Gamma: \n",
    "Use a lower gamma value when you want a smoother decision boundary and wish to avoid overfitting. A lower gamma value makes the decision boundary more generalized and less influenced by individual data points.\n",
    "\n",
    "In summary, the choice of kernel function, C parameter, epsilon parameter, and gamma parameter significantly impacts the performance of SVR. It is essential to tune these hyperparameters carefully based on the characteristics of the dataset, the expected complexity of the relationships, and the desired trade-off between fitting the training data and generalizing to unseen data. Cross-validation and grid search techniques are often used to find the optimal values for these hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0897000a-23af-402b-b508-4cf2f929eef8",
   "metadata": {},
   "source": [
    "## Q5. Assignment:\n",
    "- Import the necessary libraries and load the dataset\n",
    "- Split the dataset into training and testing sets.\n",
    "- Preprocess the data using any technique of your choice (e.g. scaling, normalization.)\n",
    "- Create an instance of the SVC classifier and train it on the training data.\n",
    "- Use the trained classifier to predict the labels of the testing data.\n",
    "- Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy, precision, recall, F1-score).\n",
    "- Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performance\n",
    "- Train the tuned classifier on the entire dataset.\n",
    "- Save the trained classifier to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b086f56d-a37c-430f-a187-a21a407cbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries and load the dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.model_selection  import train_test_split , GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23fe735c-512d-49d5-a8aa-466adb232632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets.\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "dataset = load_diabetes()\n",
    "X = dataset.data\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b280f69d-87cd-4ed7-961e-e101771d7e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test , y_train , y_test = train_test_split(X,y , test_size=.30 , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37d17bcf-4f42-4758-a2d9-87f0de689420",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess the data using any technique of your choice (e.g. scaling, normalization).\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "495d6610-c9b3-43b0-96a9-eb7ae3d3528a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create an instance of the SVC classifier and train it on the training data.\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4693202a-5125-42c4-9da1-a76a367403c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use the trained classifier to predict the labels of the testing data.\n",
    "\n",
    "y_pred = svc.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7234fd9-f316-4948-9724-d7fb12a07d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007518796992481203\n"
     ]
    }
   ],
   "source": [
    "## Evaluate the performance of the classifier using Accuracy Score \n",
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbe295ed-a9bf-4837-aea2-6502f19b3fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.016 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.033 total time=   0.1s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.033 total time=   0.1s\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 3/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 4/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END ....C=0.1, gamma=10, kernel=linear;, score=0.033 total time=   0.1s\n",
      "[CV 1/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 2/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 4/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 5/5] END .......C=0.1, gamma=10, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.032 total time=   0.1s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.032 total time=   0.1s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.032 total time=   0.1s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.032 total time=   0.1s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.032 total time=   0.1s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.032 total time=   0.1s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=10, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ......C=1, gamma=10, kernel=linear;, score=0.032 total time=   0.1s\n",
      "[CV 3/5] END ......C=1, gamma=10, kernel=linear;, score=0.032 total time=   0.1s\n",
      "[CV 4/5] END ......C=1, gamma=10, kernel=linear;, score=0.032 total time=   0.1s\n",
      "[CV 5/5] END ......C=1, gamma=10, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 1/5] END .........C=1, gamma=10, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 2/5] END .........C=1, gamma=10, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END .........C=1, gamma=10, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 4/5] END .........C=1, gamma=10, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END .........C=1, gamma=10, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.032 total time=   0.1s\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.032 total time=   0.1s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.032 total time=   0.1s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=10, kernel=linear;, score=0.000 total time=   0.1s\n",
      "[CV 2/5] END .....C=10, gamma=10, kernel=linear;, score=0.032 total time=   0.1s\n",
      "[CV 3/5] END .....C=10, gamma=10, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 4/5] END .....C=10, gamma=10, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 5/5] END .....C=10, gamma=10, kernel=linear;, score=0.016 total time=   0.1s\n",
      "[CV 1/5] END ........C=10, gamma=10, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 2/5] END ........C=10, gamma=10, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 3/5] END ........C=10, gamma=10, kernel=rbf;, score=0.016 total time=   0.1s\n",
      "[CV 4/5] END ........C=10, gamma=10, kernel=rbf;, score=0.000 total time=   0.1s\n",
      "[CV 5/5] END ........C=10, gamma=10, kernel=rbf;, score=0.000 total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [0.1, 1, 10],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [0.1, 1, 10],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;rbf&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10],\n",
       "                         'kernel': ['linear', 'rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Tune the hyperparameters of the SVC classifier using GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2fc5fd3b-5350-40e9-9d29-ca229a9bae92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6832579185520362\n"
     ]
    }
   ],
   "source": [
    "## Train the tuned classifier on the entire dataset\n",
    "\n",
    "best_svc = grid.best_estimator_\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "best_svc.fit(X_scaled, y)\n",
    "\n",
    "y_pred1 = best_svc.predict(X_scaled)\n",
    "\n",
    "print(accuracy_score(y_pred1,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94af5f4a-d4f7-4d21-9dda-276c7493bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Save the trained classifier to a file for future use.\n",
    "\n",
    "pickle.dump(scaler,open(\"scaler.pkl\",'wb'))\n",
    "pickle.dump(best_svc,open(\"best_svc.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a04b9-ae1b-438f-b599-d9c4e5902f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
